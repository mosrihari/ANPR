{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T00:36:56.819759Z","iopub.execute_input":"2021-06-01T00:36:56.820186Z","iopub.status.idle":"2021-06-01T00:36:56.826938Z","shell.execute_reply.started":"2021-06-01T00:36:56.8201Z","shell.execute_reply":"2021-06-01T00:36:56.825709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2021-06-01T00:37:39.754657Z","iopub.execute_input":"2021-06-01T00:37:39.755064Z","iopub.status.idle":"2021-06-01T00:38:58.607558Z","shell.execute_reply.started":"2021-06-01T00:37:39.755029Z","shell.execute_reply":"2021-06-01T00:38:58.606215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/drive/folders/1Yio34S3msz33Vdf-01WNZlUbZaE8dQci?usp=sharing","metadata":{"execution":{"iopub.status.busy":"2021-06-01T00:42:09.227597Z","iopub.execute_input":"2021-06-01T00:42:09.22797Z","iopub.status.idle":"2021-06-01T00:42:11.136217Z","shell.execute_reply.started":"2021-06-01T00:42:09.227936Z","shell.execute_reply":"2021-06-01T00:42:11.134607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import resnet50\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\ndef create_model(output_shape, lr=0.0001, training=False):\n    base_model = resnet50.ResNet50(weights=\"imagenet\",include_top=False,input_tensor=Input(shape=(80,80,3)))\n    headModel = base_model.output\n    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n    headModel = Flatten(name=\"flatten\")(headModel)\n    headModel = Dense(128, activation=\"relu\")(headModel)\n    headModel = Dropout(0.5)(headModel)\n    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n    \n    model = Model(inputs=base_model.input, outputs=headModel)\n    # Training params\n    if training:\n        for layer in base_model.layers:\n            layer.trainable = True\n        optimizer = Adam(lr=lr)\n        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n        \n    return model\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\nDIRECTORY = \"../input/dataset-recog/dataset_characters\"\ntrain_datagen_dir = train_datagen.flow_from_directory(directory=DIRECTORY,target_size=(80,80), batch_size=32,\n                                                      subset=\"training\")\n\nvalidation_datagen_dir = train_datagen.flow_from_directory(directory=DIRECTORY,target_size=(80,80), batch_size=32,\n                                                      subset=\"validation\")\nmodel = create_model(output_shape=36, training=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T00:49:13.102821Z","iopub.execute_input":"2021-06-01T00:49:13.103205Z","iopub.status.idle":"2021-06-01T00:49:18.141031Z","shell.execute_reply.started":"2021-06-01T00:49:13.103173Z","shell.execute_reply":"2021-06-01T00:49:18.139801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_datagen_dir,epochs=30,validation_data=validation_datagen_dir)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T00:49:18.143335Z","iopub.execute_input":"2021-06-01T00:49:18.144263Z","iopub.status.idle":"2021-06-01T01:50:05.922584Z","shell.execute_reply.started":"2021-06-01T00:49:18.144188Z","shell.execute_reply":"2021-06-01T01:50:05.92152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import save_model\n\nsave_model(model, \"dataset_recog_resnet.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:54:05.878052Z","iopub.execute_input":"2021-06-01T01:54:05.878449Z","iopub.status.idle":"2021-06-01T01:54:06.960427Z","shell.execute_reply.started":"2021-06-01T01:54:05.878417Z","shell.execute_reply":"2021-06-01T01:54:06.959334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mobilenet","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.models import model_from_json\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport glob\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:30:52.663530Z","iopub.execute_input":"2021-06-01T06:30:52.663863Z","iopub.status.idle":"2021-06-01T06:30:59.269120Z","shell.execute_reply.started":"2021-06-01T06:30:52.663830Z","shell.execute_reply":"2021-06-01T06:30:59.268231Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset_paths = glob.glob(\"../input/dataset-recog/dataset_characters/**/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:31:17.154039Z","iopub.execute_input":"2021-06-01T06:31:17.154348Z","iopub.status.idle":"2021-06-01T06:31:21.927335Z","shell.execute_reply.started":"2021-06-01T06:31:17.154319Z","shell.execute_reply":"2021-06-01T06:31:21.926459Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nX=[]\nlabels=[]\n\nfor image_path in dataset_paths:\n  label = image_path.split(os.path.sep)[-2]\n  image=load_img(image_path,target_size=(80,80))\n  image=img_to_array(image)\n\n  X.append(image)\n  labels.append(label)\n\nX = np.array(X,dtype=\"float16\")\nlabels = np.array(labels)\n\nprint(\"[INFO] Find {:d} images with {:d} classes\".format(len(X),len(set(labels))))\n\n\n# perform one-hot encoding on the labels\nlb = LabelEncoder()\nlb.fit(labels)\nlabels = lb.transform(labels)\ny = to_categorical(labels)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:31:21.929069Z","iopub.execute_input":"2021-06-01T06:31:21.929400Z","iopub.status.idle":"2021-06-01T06:34:08.954380Z","shell.execute_reply.started":"2021-06-01T06:31:21.929365Z","shell.execute_reply":"2021-06-01T06:34:08.953387Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[INFO] Find 37623 images with 36 classes\n","output_type":"stream"}]},{"cell_type":"code","source":"(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:34:08.956075Z","iopub.execute_input":"2021-06-01T06:34:08.956330Z","iopub.status.idle":"2021-06-01T06:34:10.765604Z","shell.execute_reply.started":"2021-06-01T06:34:08.956306Z","shell.execute_reply":"2021-06-01T06:34:10.764579Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"image_gen = ImageDataGenerator(rotation_range=10,\n                              width_shift_range=0.1,\n                              height_shift_range=0.1,\n                              shear_range=0.1,\n                              zoom_range=0.1,\n                              fill_mode=\"nearest\"\n                              )","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:34:10.767176Z","iopub.execute_input":"2021-06-01T06:34:10.767507Z","iopub.status.idle":"2021-06-01T06:34:10.772766Z","shell.execute_reply.started":"2021-06-01T06:34:10.767471Z","shell.execute_reply":"2021-06-01T06:34:10.771856Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\n    baseModel = EfficientNetB3(weights=\"imagenet\", \n                            include_top=False,\n                            input_tensor=Input(shape=(80, 80, 3)))\n\n    headModel = baseModel.output\n    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n    headModel = Flatten(name=\"flatten\")(headModel)\n    headModel = Dense(128, activation=\"relu\")(headModel)\n    headModel = Dropout(0.5)(headModel)\n    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n    \n    model = Model(inputs=baseModel.input, outputs=headModel)\n    \n    if training:\n        # define trainable lalyer\n        for layer in baseModel.layers:\n            layer.trainable = True\n        # compile model\n        optimizer = Adam(lr=lr, decay = decay)\n        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:34:10.774657Z","iopub.execute_input":"2021-06-01T06:34:10.775325Z","iopub.status.idle":"2021-06-01T06:34:10.784823Z","shell.execute_reply.started":"2021-06-01T06:34:10.775285Z","shell.execute_reply":"2021-06-01T06:34:10.783986Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"INIT_LR = 1e-4\nEPOCHS = 30\n\nmodel = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:34:10.786404Z","iopub.execute_input":"2021-06-01T06:34:10.786849Z","iopub.status.idle":"2021-06-01T06:34:16.231432Z","shell.execute_reply.started":"2021-06-01T06:34:10.786810Z","shell.execute_reply":"2021-06-01T06:34:16.230569Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n43941888/43941136 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 64\n\nmy_checkpointer = [\n                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n                ModelCheckpoint(filepath=\"License_character_recognition.h5\", verbose=1, save_weights_only=True)\n                ]\n\nresult = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE), \n                   steps_per_epoch=len(trainX) // BATCH_SIZE, \n                   validation_data=(testX, testY), \n                   validation_steps=len(testX) // BATCH_SIZE, \n                   epochs=EPOCHS, callbacks=my_checkpointer)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T06:34:16.236127Z","iopub.execute_input":"2021-06-01T06:34:16.238161Z","iopub.status.idle":"2021-06-01T07:05:55.303174Z","shell.execute_reply.started":"2021-06-01T06:34:16.238111Z","shell.execute_reply":"2021-06-01T07:05:55.302191Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/30\n529/529 [==============================] - 107s 168ms/step - loss: 2.5356 - accuracy: 0.3430 - val_loss: 0.4000 - val_accuracy: 0.8982\n\nEpoch 00001: saving model to License_character_recognition.h5\nEpoch 2/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.4113 - accuracy: 0.8940 - val_loss: 0.1942 - val_accuracy: 0.9487\n\nEpoch 00002: saving model to License_character_recognition.h5\nEpoch 3/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.2527 - accuracy: 0.9321 - val_loss: 0.1523 - val_accuracy: 0.9559\n\nEpoch 00003: saving model to License_character_recognition.h5\nEpoch 4/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.1877 - accuracy: 0.9476 - val_loss: 0.1177 - val_accuracy: 0.9647\n\nEpoch 00004: saving model to License_character_recognition.h5\nEpoch 5/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.1608 - accuracy: 0.9536 - val_loss: 0.1108 - val_accuracy: 0.9665\n\nEpoch 00005: saving model to License_character_recognition.h5\nEpoch 6/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.1300 - accuracy: 0.9615 - val_loss: 0.0843 - val_accuracy: 0.9718\n\nEpoch 00006: saving model to License_character_recognition.h5\nEpoch 7/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.1191 - accuracy: 0.9653 - val_loss: 0.0788 - val_accuracy: 0.9769\n\nEpoch 00007: saving model to License_character_recognition.h5\nEpoch 8/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.1057 - accuracy: 0.9684 - val_loss: 0.0803 - val_accuracy: 0.9756\n\nEpoch 00008: saving model to License_character_recognition.h5\nEpoch 9/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.1059 - accuracy: 0.9683 - val_loss: 0.0708 - val_accuracy: 0.9771\n\nEpoch 00009: saving model to License_character_recognition.h5\nEpoch 10/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.0848 - accuracy: 0.9733 - val_loss: 0.0624 - val_accuracy: 0.9790\n\nEpoch 00010: saving model to License_character_recognition.h5\nEpoch 11/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.0807 - accuracy: 0.9742 - val_loss: 0.0692 - val_accuracy: 0.9779\n\nEpoch 00011: saving model to License_character_recognition.h5\nEpoch 12/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.0721 - accuracy: 0.9765 - val_loss: 0.0602 - val_accuracy: 0.9819\n\nEpoch 00012: saving model to License_character_recognition.h5\nEpoch 13/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.0739 - accuracy: 0.9761 - val_loss: 0.0650 - val_accuracy: 0.9798\n\nEpoch 00013: saving model to License_character_recognition.h5\nEpoch 14/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.0699 - accuracy: 0.9781 - val_loss: 0.0608 - val_accuracy: 0.9811\n\nEpoch 00014: saving model to License_character_recognition.h5\nEpoch 15/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.0625 - val_accuracy: 0.9801\n\nEpoch 00015: saving model to License_character_recognition.h5\nEpoch 16/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.0640 - accuracy: 0.9792 - val_loss: 0.0644 - val_accuracy: 0.9814\n\nEpoch 00016: saving model to License_character_recognition.h5\nEpoch 17/30\n529/529 [==============================] - 86s 163ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0467 - val_accuracy: 0.9841\n\nEpoch 00017: saving model to License_character_recognition.h5\nEpoch 18/30\n529/529 [==============================] - 83s 157ms/step - loss: 0.0607 - accuracy: 0.9805 - val_loss: 0.0579 - val_accuracy: 0.9827\n\nEpoch 00018: saving model to License_character_recognition.h5\nEpoch 19/30\n529/529 [==============================] - 86s 163ms/step - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.0602 - val_accuracy: 0.9825\n\nEpoch 00019: saving model to License_character_recognition.h5\nEpoch 20/30\n529/529 [==============================] - 86s 162ms/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.0615 - val_accuracy: 0.9798\n\nEpoch 00020: saving model to License_character_recognition.h5\nEpoch 21/30\n529/529 [==============================] - 84s 159ms/step - loss: 0.0522 - accuracy: 0.9848 - val_loss: 0.0606 - val_accuracy: 0.9833\n\nEpoch 00021: saving model to License_character_recognition.h5\nEpoch 22/30\n529/529 [==============================] - 85s 160ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0536 - val_accuracy: 0.9827\n\nEpoch 00022: saving model to License_character_recognition.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# save model architectur as json file\nmodel_json = model.to_json()\nwith open(\"EfficientNet_character_recognition.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:06:10.093966Z","iopub.execute_input":"2021-06-01T07:06:10.094300Z","iopub.status.idle":"2021-06-01T07:06:10.197236Z","shell.execute_reply.started":"2021-06-01T07:06:10.094270Z","shell.execute_reply":"2021-06-01T07:06:10.196363Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}